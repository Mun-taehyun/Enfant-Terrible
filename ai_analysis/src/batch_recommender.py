import pandas as pd
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from sqlalchemy import create_engine, text
import os
import time

# --- ê²½ë¡œ ë° DB ì„¤ì • ---
current_file_path = os.path.abspath(__file__) 
base_dir = os.path.dirname(os.path.dirname(current_file_path)) 
RAW_PATH = os.path.join(base_dir, "data", "raw")
PROCESSED_PATH = os.path.join(base_dir, "data", "processed")

# ë³¸ì¸ì˜ ê³„ì • ì •ë³´ë¡œ ìˆ˜ì • (C##ENFANT ë˜ëŠ” ENFANT)
DB_URL = 'oracle+cx_oracle://ENFANT:1234@localhost:1521/?service_name=xe'
engine = create_engine(DB_URL)

def run_batch_recommendations(limit_users=100):
    start_time = time.time()
    print(f"ğŸš€ [Enfant Terrible] {limit_users}ëª… ëŒ€ìƒ ëŒ€ëŸ‰ ì¶”ì²œ ì—…ë°ì´íŠ¸ ì‹œì‘...")

    try:
        # 1. ë°ì´í„° ë¡œë“œ
        df_scores = pd.read_csv(os.path.join(PROCESSED_PATH, "integrated_score_v2.csv"))
        df_profiles = pd.read_csv(os.path.join(RAW_PATH, "dog_profiles.csv"))
        
        # 2. ì—…ë°ì´íŠ¸í•  ìœ ì € ìƒ˜í”Œë§ (í™œë™ì´ ìˆëŠ” ìœ ì € ì¤‘ ìƒìœ„ Nëª…)
        target_users = df_scores['user_id'].unique()[:limit_users]
        
        print(f"ğŸ“Š ì´ {len(target_users)}ëª…ì˜ ìœ ì €ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.")

        with engine.connect() as conn:
            for idx, user_id in enumerate(target_users):
                # ê¸°ì¡´ ì¶”ì²œ ì‚­ì œ
                conn.execute(text("DELETE FROM ET_USER_RECOMMENDATION WHERE USER_ID = :u_id"), {"u_id": int(user_id)})
                
                # --- ì¶”ì²œ ë¡œì§ (ìœ ì‚¬ ê·¸ë£¹ ê¸°ë°˜) ---
                user_info = df_profiles[df_profiles['user_id'] == user_id]
                if user_info.empty: continue
                
                t_age, t_size = user_info.iloc[0]['dog_age'], user_info.iloc[0]['dog_size']
                peer_ids = df_profiles[(df_profiles['dog_age']==t_age) & (df_profiles['dog_size']==t_size)]['user_id'].unique()
                
                # ìœ ì‚¬ ê·¸ë£¹ ìƒ˜í”Œë§ (ê³„ì‚° ì†ë„ í–¥ìƒ)
                if len(peer_ids) > 1000:
                    peer_ids = np.random.choice(peer_ids, 1000, replace=False)
                sample_ids = np.unique(np.append(peer_ids, user_id))
                
                df_sub = df_scores[df_scores['user_id'].isin(sample_ids)]
                matrix = df_sub.pivot_table(index='user_id', columns='product_id', values='total_score').fillna(0)
                
                # ìœ ì‚¬ë„ ë° ê°€ì¤‘ì¹˜ ê³„ì‚°
                user_sim = cosine_similarity(matrix)
                user_sim_df = pd.DataFrame(user_sim, index=matrix.index, columns=matrix.index)
                
                similar_users = user_sim_df[user_id].sort_values(ascending=False)[1:11]
                sim_user_data = matrix.loc[similar_users.index]
                weights = similar_users.values.reshape(-1, 1)
                
                weighted_scores = (sim_user_data * weights).sum(axis=0) / (weights.sum() + 1e-9)
                purchased = df_scores[df_scores['user_id'] == user_id]['product_id'].unique()
                recommendations = weighted_scores.drop(purchased, errors='ignore').sort_values(ascending=False).head(5)

                # --- DB ì €ì¥ ---
                for rank, (p_id, score) in enumerate(recommendations.items(), 1):
                    conn.execute(text("""
                        INSERT INTO ET_USER_RECOMMENDATION (RECOMMENDATION_ID, USER_ID, PRODUCT_ID, RANK_NO, SCORE)
                        VALUES (ET_RECO_SEQ.NEXTVAL, :u_id, :p_id, :rank, :score)
                    """), {"u_id": int(user_id), "p_id": int(p_id), "rank": rank, "score": float(score)})
                
                if (idx + 1) % 10 == 0:
                    print(f"â³ ì§„í–‰ ì¤‘... ({idx + 1}/{len(target_users)})")
            
            conn.commit() # ìµœì¢… ì»¤ë°‹

        print(f"âœ… ëŒ€ëŸ‰ ì—…ë°ì´íŠ¸ ì™„ë£Œ! (ì†Œìš” ì‹œê°„: {time.time() - start_time:.2f}ì´ˆ)")

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")

if __name__ == "__main__":
    run_batch_recommendations(limit_users=500) # 500ëª… í…ŒìŠ¤íŠ¸