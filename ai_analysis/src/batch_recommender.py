import pandas as pd
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from sqlalchemy import create_engine, text
import os
import time

# --- ê²½ë¡œ ì„¤ì • ---
current_file_path = os.path.abspath(__file__) 
base_dir = os.path.dirname(os.path.dirname(current_file_path)) 
PROCESSED_PATH = os.path.join(base_dir, "data", "processed")

# 1. MySQL DB ì—°ê²° ì„¤ì • ìˆ˜ì • (DB ì´ë¦„: enfant_terrible)
DB_URL = 'mysql+pymysql://enfant:1234@localhost:3306/enfant_terrible?charset=utf8mb4'
engine = create_engine(DB_URL)

def run_batch_recommendations_erd(limit_users=100):
    start_time = time.time()
    # 2. ë¡œê·¸ ë©”ì‹œì§€ ìˆ˜ì •
    print(f"ğŸš€ [Enfant Terrible] ì‹ ê·œ DB(enfant_terrible) ê¸°ë°˜ {limit_users}ëª… ì¶”ì²œ ë°°ì¹˜ ì‹œì‘...")

    try:
        score_file = os.path.join(PROCESSED_PATH, "integrated_score_v2.csv")
        if not os.path.exists(score_file):
            print("âŒ ì „ì²˜ë¦¬ëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return
            
        df_scores = pd.read_csv(score_file)
        matrix = df_scores.pivot_table(index='user_id', columns='product_id', values='total_score').fillna(0)
        
        # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
        user_sim = cosine_similarity(matrix)
        user_sim_df = pd.DataFrame(user_sim, index=matrix.index, columns=matrix.index)

        recommendation_data = []
        target_users = matrix.index[:limit_users]

        for user_id in target_users:
            similar_users = user_sim_df[user_id].sort_values(ascending=False)[1:11]
            sim_user_data = matrix.loc[similar_users.index]
            weights = similar_users.values.reshape(-1, 1)
            
            weighted_scores = (sim_user_data * weights).sum(axis=0) / (weights.sum() + 1e-9)
            
            # ì´ë¯¸ êµ¬ë§¤í•œ ìƒí’ˆ ì œì™¸
            purchased = df_scores[df_scores['user_id'] == user_id]['product_id'].unique()
            recs = weighted_scores.drop(purchased, errors='ignore').sort_values(ascending=False).head(5)

            for r_idx, (p_id, score) in enumerate(recs.items(), 1):
                recommendation_data.append({
                    "u_id": int(user_id),
                    "p_id": int(p_id),
                    "rank_val": r_idx, 
                    "score_val": round(float(score), 4)
                })

        # 3. DB ì €ì¥ (enfant_terrible ë‚´ et_user_recommendation í…Œì´ë¸”)
        print(f"ğŸš€ {len(recommendation_data)}ê±´ì˜ ë°ì´í„°ë¥¼ et_user_recommendationì— ë°˜ì˜ ì¤‘...")
        with engine.connect() as conn:
            conn.execute(text("SET FOREIGN_KEY_CHECKS = 0;"))
            conn.execute(text("TRUNCATE TABLE et_user_recommendation;"))
            conn.execute(text("SET FOREIGN_KEY_CHECKS = 1;"))
            
            # `rank`ëŠ” ì˜ˆì•½ì–´ì´ë¯€ë¡œ ë°±í‹±(``) í•„ìˆ˜ ì‚¬ìš©
            insert_query = text("""
                INSERT INTO et_user_recommendation (user_id, product_id, `rank`, score)
                VALUES (:u_id, :p_id, :rank_val, :score_val)
            """)
            
            conn.execute(insert_query, recommendation_data)
            conn.commit()

        print(f"âœ… enfant_terrible DB ìµœì í™” ì¶”ì²œ ì™„ë£Œ! (ì†Œìš” ì‹œê°„: {time.time() - start_time:.2f}ì´ˆ)")

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")

if __name__ == "__main__":
    run_batch_recommendations_erd(limit_users=100)