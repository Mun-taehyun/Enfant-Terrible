import pandas as pd
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from sqlalchemy import create_engine, text
import os
import time

# --- ì„¤ì • ë™ì¼ ---
current_file_path = os.path.abspath(__file__) 
base_dir = os.path.dirname(os.path.dirname(current_file_path)) 
RAW_PATH = os.path.join(base_dir, "data", "raw")
PROCESSED_PATH = os.path.join(base_dir, "data", "processed")

DB_URL = 'mysql+pymysql://enfant:1234@localhost:3306/enfant_db?charset=utf8mb4'
engine = create_engine(DB_URL)

def run_batch_recommendations(limit_users=5000):
    start_time = time.time()
    print(f"ğŸš€ [Enfant Terrible] {limit_users}ëª… ëŒ€ìƒ ëŒ€ëŸ‰ ì¶”ì²œ ì‹œì‘...")

    try:
        # 1. ë°ì´í„° ë¡œë“œ
        df_scores = pd.read_csv(os.path.join(PROCESSED_PATH, "integrated_score_v2.csv"))
        
        # 2. ì „ì²´ ìœ ì €-ìƒí’ˆ í–‰ë ¬ ìƒì„± (í•œ ë²ˆë§Œ ìˆ˜í–‰)
        print("âš™ï¸ ì „ì²´ ìœ ì € í–‰ë ¬ ìƒì„± ë° ìœ ì‚¬ë„ ê³„ì‚° ì¤‘...")
        matrix = df_scores.pivot_table(index='user_id', columns='product_id', values='total_score').fillna(0)
        
        # ì „ì²´ ìœ ì € ê°„ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚° (5000x5000 í–‰ë ¬ì€ ê¸ˆë°© ê³„ì‚°ë©ë‹ˆë‹¤)
        user_sim = cosine_similarity(matrix)
        user_sim_df = pd.DataFrame(user_sim, index=matrix.index, columns=matrix.index)

        # 3. ì¶”ì²œ ê²°ê³¼ ìˆ˜ì§‘ (ë©”ëª¨ë¦¬ì—ì„œ ì²˜ë¦¬ í›„ í•œêº¼ë²ˆì— DB ì €ì¥)
        target_users = matrix.index[:limit_users]
        recommendation_data = []

        print(f"ğŸ§  {len(target_users)}ëª… ìœ ì €ì˜ ì¶”ì²œ ì•„ì´í…œ ê³„ì‚° ì¤‘...")
        for user_id in target_users:
            # ìœ ì‚¬ ìœ ì € ìƒìœ„ 20ëª… ì¶”ì¶œ
            similar_users = user_sim_df[user_id].sort_values(ascending=False)[1:21]
            sim_user_data = matrix.loc[similar_users.index]
            weights = similar_users.values.reshape(-1, 1)
            
            # ê°€ì¤‘ í‰ê·  ì ìˆ˜ ê³„ì‚°
            weighted_scores = (sim_user_data * weights).sum(axis=0) / (weights.sum() + 1e-9)
            
            # ì´ë¯¸ êµ¬ë§¤í•œ ìƒí’ˆ ì œì™¸
            purchased = df_scores[df_scores['user_id'] == user_id]['product_id'].unique()
            recs = weighted_scores.drop(purchased, errors='ignore').sort_values(ascending=False).head(5)

            for rank, (p_id, score) in enumerate(recs.items(), 1):
                recommendation_data.append({
                    "u_id": int(user_id),
                    "p_id": int(p_id),
                    "rank": rank,
                    "score": float(score)
                })

        # 4. DB ëŒ€ëŸ‰ ì €ì¥ (Bulk Insert)
        print(f"ğŸš€ {len(recommendation_data)}ê±´ì˜ ë°ì´í„°ë¥¼ DBì— ì „ì†¡ ì¤‘...")
        with engine.connect() as conn:
            # ì „ì²´ ì´ˆê¸°í™” (ë°°ì¹˜ ì‘ì—…ì´ë¯€ë¡œ ê¸°ì¡´ ë°ì´í„°ë¥¼ ë¹„ìš°ê³  ì‹œì‘í•˜ëŠ” ê²ƒì´ ê¹”ë”í•©ë‹ˆë‹¤)
            conn.execute(text("TRUNCATE TABLE et_user_recommendation"))
            
            # íš¨ìœ¨ì ì¸ ëŒ€ëŸ‰ ì €ì¥ì„ ìœ„í•œ ì¿¼ë¦¬
            insert_query = text("""
                INSERT INTO et_user_recommendation (USER_ID, PRODUCT_ID, RANK_NO, SCORE)
                VALUES (:u_id, :p_id, :rank, :score)
            """)
            
            # ë¦¬ìŠ¤íŠ¸ í˜•íƒœì˜ ë°ì´í„°ë¥¼ í•œêº¼ë²ˆì— ì²˜ë¦¬
            conn.execute(insert_query, recommendation_data)
            conn.commit()

        print(f"âœ… ëŒ€ëŸ‰ ì—…ë°ì´íŠ¸ ì™„ë£Œ! (ì†Œìš” ì‹œê°„: {time.time() - start_time:.2f}ì´ˆ)")

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")

if __name__ == "__main__":
    # ì „ì²´ ìœ ì € 5,000ëª…ì„ ëŒ€ìƒìœ¼ë¡œ ì‹¤í–‰
    run_batch_recommendations(limit_users=5000)