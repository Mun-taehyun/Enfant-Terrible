import pandas as pd
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from sqlalchemy import create_engine, text
import os
import time

# --- ê²½ë¡œ ì„¤ì • ---
current_file_path = os.path.abspath(__file__) 
base_dir = os.path.dirname(os.path.dirname(current_file_path)) 
PROCESSED_PATH = os.path.join(base_dir, "data", "processed")

# MySQL DB ì—°ê²° ì„¤ì • (ì‚¬ìš©ì: enfant)
DB_URL = 'mysql+pymysql://enfant:1234@localhost:3306/enfant_db?charset=utf8mb4'
engine = create_engine(DB_URL)

def run_full_batch_recommendation_erd(top_n=5):
    try:
        start_time = time.time()
        print(f"ğŸš€ [Enfant Terrible] ERD ê¸°ë°˜ ì¶”ì²œ ë°°ì¹˜ ì‹œì‘...")

        # 1. ë°ì´í„° ë¡œë”©
        file_path = os.path.join(PROCESSED_PATH, "integrated_score_v2.csv")
        if not os.path.exists(file_path):
            print(f"âŒ ì „ì²˜ë¦¬ëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {file_path}")
            return
        df_scores = pd.read_csv(file_path)
        
        # 2. ìœ ì‚¬ë„ ê³„ì‚°
        user_item_matrix = df_scores.pivot_table(index='user_id', columns='product_id', values='total_score').fillna(0)
        user_sim = cosine_similarity(user_item_matrix)
        user_sim_df = pd.DataFrame(user_sim, index=user_item_matrix.index, columns=user_item_matrix.index)
        
        # 3. ì¶”ì²œ ê³„ì‚° ë° ë¦¬ìŠ¤íŠ¸ ìƒì„±
        all_recommendations = []
        for target_user_id in user_item_matrix.index:
            similar_users = user_sim_df[target_user_id].sort_values(ascending=False)[1:11]
            sim_user_data = user_item_matrix.loc[similar_users.index]
            weights = similar_users.values.reshape(-1, 1)
            
            weighted_scores = (sim_user_data * weights).sum(axis=0) / (weights.sum() + 1e-9)
            purchased = df_scores[df_scores['user_id'] == target_user_id]['product_id'].unique()
            recommendations = weighted_scores.drop(purchased, errors='ignore').sort_values(ascending=False).head(top_n)

            for r_idx, (p_id, score) in enumerate(recommendations.items(), 1):
                all_recommendations.append({
                    "user_id": int(target_user_id),
                    "product_id": int(p_id),
                    "rank": int(r_idx),
                    "score": float(round(score, 4))
                })

        # 4. DB ì €ì¥ (Pandas to_sql ë°©ì‹ - ë°”ì¸ë”© ì—ëŸ¬ 100% í•´ê²°)
        print(f"ğŸ’¾ MySQL 'et_user_recommendation' í…Œì´ë¸” ì—…ë°ì´íŠ¸ ì¤‘...")
        
        # ë¦¬ìŠ¤íŠ¸ë¥¼ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜
        result_df = pd.DataFrame(all_recommendations)

        with engine.begin() as conn:
            # 1ë‹¨ê³„: ê¸°ì¡´ ì¶”ì²œ ë°ì´í„° ì‚­ì œ (TRUNCATE)
            conn.execute(text("TRUNCATE TABLE et_user_recommendation;"))
            
            # 2ë‹¨ê³„: ë°ì´í„°í”„ë ˆì„ì„ DB í…Œì´ë¸”ì— ì§ì ‘ ë°€ì–´ë„£ê¸°
            # index=FalseëŠ” í–‰ ë²ˆí˜¸ë¥¼ ë„£ì§€ ì•Šê² ë‹¤ëŠ” ëœ»ì…ë‹ˆë‹¤.
            result_df.to_sql(
                name='et_user_recommendation', 
                con=conn, 
                if_exists='append', 
                index=False,
                method='multi' # ì—¬ëŸ¬ í–‰ì„ í•œ ë²ˆì— ì‚½ì…í•˜ì—¬ ì„±ëŠ¥ ìµœì í™”
            )
            
        print(f"âœ¨ ë°°ì¹˜ ì™„ë£Œ! (ì†Œìš” ì‹œê°„: {time.time() - start_time:.2f}ì´ˆ)")
        print(f"âœ… DB í™•ì¸: {len(all_recommendations)}ê°œì˜ ë°ì´í„°ê°€ 'et_user_recommendation'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ ìƒì„¸: {e}")

if __name__ == "__main__":
    run_full_batch_recommendation_erd()